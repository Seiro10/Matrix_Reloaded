services:
  redis:
    image: redis:7-alpine
    container_name: rss_redis
    ports:
      - "6379:6379"
    networks:
      - content-agents  # Use same network as router agent
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  rss-agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rss_agent_main
    restart: unless-stopped
    ports:
      - "8086:8086"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - PORT=8086
    env_file:
      - .env
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - content-agents
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    user: "1000:1000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: "3"

  rss-agent-worker:
    build: .
    command: celery -A core.queue_manager.celery_app worker --loglevel=info --queues=scraping,processing,uploads --concurrency=2
    environment:
      - ROUTER_AGENT_URL=http://matrix_reloaded-router-agent-1:8080
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - content-agents

  rss-agent-flower:
    build: .
    command: celery -A core.queue_manager.celery_app flower --port=5555
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - redis
    networks:
      - content-agents

  celery-scraping:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rss_celery_scraping
    restart: unless-stopped
    environment:
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    env_file:
      - .env
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    user: "1000:1000"
    networks:
      - rss_network
    command: >
      celery -A core.queue_manager.celery_app worker --loglevel=info
      --queues=scraping --concurrency=2 --hostname=scraper@%h
    healthcheck:
      test: ["CMD", "celery", "-A", "core.queue_manager.celery_app", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: "3"

  celery-processing:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rss_celery_processing
    restart: unless-stopped
    environment:
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:redis@6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    env_file:
      - .env
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    user: "1000:1000"
    networks:
      - rss_network
    command: >
      celery -A core.queue_manager.celery_app worker --loglevel=info
      --queues=processing --concurrency=4 --hostname=processor@%h
    healthcheck:
      test: ["CMD", "celery", "-A", "core.queue_manager.celery_app", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: "3"

  celery-uploads:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rss_celery_uploads
    restart: unless-stopped
    environment:
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    env_file:
      - .env
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    user: "1000:1000"
    networks:
      - rss_network
    command: >
      celery -A core.queue_manager.celery_app worker --loglevel=info
      --queues=uploads --concurrency=10 --hostname=uploader@%h
    healthcheck:
      test: ["CMD", "celery", "-A", "core.queue_manager.celery_app", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: "3"

  celery-flower:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rss_celery_flower
    restart: unless-stopped
    ports:
      - "5555:5555"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - rss_network
    command: >
      celery -A core.queue_manager.celery_app flower --port=5555
      --broker=redis://redis:6379/0
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:5555/api/workers"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: "3"

volumes:
  redis_data:
    driver: local

networks:
  content-agents:
    external: true
    name: matrix_reloaded_content-agents
